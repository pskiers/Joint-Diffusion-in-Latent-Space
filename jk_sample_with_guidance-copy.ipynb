{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jk/miniconda3/envs/ldm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-28 10:40:29.412168: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-28 10:40:29.416377: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-28 10:40:29.487347: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-28 10:40:30.427705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import umap\n",
    "from models import JointLatentDiffusionMultilabel, MultilabelClassifier\n",
    "from datasets import ChestXRay_nih_bbox\n",
    "import torchvision as tv\n",
    "from ldm.util import default\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from ldm.models.diffusion.ddim import DDIMSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JointLatentDiffusionMultilabel: Running in eps-prediction mode\n",
      "DiffusionWrapper has 402.65 M params.\n",
      "Keeping EMAs of 308.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Restored from /home/jk/Joint-Diffusion-in-Latent-Space/logs/compvis32x32x4_all_randomresizedcrop_Autoencoder_2024-01-17T13-15-27/checkpoints/epoch=000025.ckpt\n",
      "Training JointLatentDiffusionMultilabel as an unconditional model.\n",
      "Keeping EMAs of 312.\n",
      "Restored from logs/a8_jd_lr10_4_14cls_JointLatentDiffusionMultilabel_2024-02-09T07-02-07/checkpoints/last.ckpt with 0 missing and 0 unexpected keys\n",
      "WARNING AUROC HARDCODEDDDD to 14 classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jk/miniconda3/envs/ldm/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JointLatentDiffusionMultilabel(\n",
       "  (model): DiffusionWrapper(\n",
       "    (diffusion_model): AdjustedUNet(\n",
       "      (time_embed): Sequential(\n",
       "        (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (input_blocks): ModuleList(\n",
       "        (0): TimestepEmbedSequential(\n",
       "          (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(320, 960, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(320, 320, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (3): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (4): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(640, 1920, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(640, 640, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (5): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(640, 1920, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(640, 640, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (6): TimestepEmbedSequential(\n",
       "          (0): Downsample(\n",
       "            (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (7): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(1280, 3840, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(1280, 1280, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (8): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Identity()\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(1280, 3840, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(1280, 1280, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (middle_block): TimestepEmbedSequential(\n",
       "        (0): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1280, 3840, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttentionLegacy()\n",
       "          (proj_out): Conv1d(1280, 1280, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (h_upd): Identity()\n",
       "          (x_upd): Identity()\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (output_blocks): ModuleList(\n",
       "        (0-1): 2 x TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(1280, 3840, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(1280, 1280, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (2): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(1280, 3840, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(1280, 1280, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(640, 1920, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(640, 640, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (4): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(640, 1920, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(640, 640, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (5): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(640, 1920, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(640, 640, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (6): TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(320, 960, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(320, 320, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (7-8): 2 x TimestepEmbedSequential(\n",
       "          (0): ResBlock(\n",
       "            (in_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (h_upd): Identity()\n",
       "            (x_upd): Identity()\n",
       "            (emb_layers): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "            (out_layers): Sequential(\n",
       "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "              (1): SiLU()\n",
       "              (2): Dropout(p=0, inplace=False)\n",
       "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "            (qkv): Conv1d(320, 960, kernel_size=(1,), stride=(1,))\n",
       "            (attention): QKVAttentionLegacy()\n",
       "            (proj_out): Conv1d(320, 320, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (out): Sequential(\n",
       "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (model_ema): LitEma()\n",
       "  (first_stage_model): AutoencoderKL(\n",
       "    (encoder): Encoder(\n",
       "      (conv_in): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (down): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): Downsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (3): Module(\n",
       "          (block): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "      )\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (mid): Module(\n",
       "        (block_1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (attn_1): AttnBlock(\n",
       "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (block_2): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1-2): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1-2): 2 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2-3): 2 x Module(\n",
       "          (block): ModuleList(\n",
       "            (0-2): 3 x ResnetBlock(\n",
       "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): Upsample(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "      (conv_out): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (loss): Identity()\n",
       "    (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=26240, out_features=3280, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=3280, out_features=14, bias=True)\n",
       "  )\n",
       "  (auroc_train): AUROC()\n",
       "  (auroc_val): AUROC()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config = OmegaConf.load(\"logs/a2_jd_classweight0_001_JointLatentDiffusionMultilabel_2024-02-08T16-53-13/configs/config.yaml\")\n",
    "# config.model.params[\"ckpt_path\"] = f\"logs/a2_jd_classweight0_001_JointLatentDiffusionMultilabel_2024-02-08T16-53-13/checkpoints/last.ckpt\"\n",
    "\n",
    "# config = OmegaConf.load(\"logs/a7_jd_lr10_4_bcew_JointLatentDiffusionMultilabel_2024-02-09T03-14-54/configs/config.yaml\")\n",
    "# config.model.params[\"ckpt_path\"] = f\"logs/a7_jd_lr10_4_bcew_JointLatentDiffusionMultilabel_2024-02-09T03-14-54/checkpoints/last.ckpt\"\n",
    "\n",
    "config = OmegaConf.load(\"logs/a8_jd_lr10_4_14cls_JointLatentDiffusionMultilabel_2024-02-09T07-02-07/configs/config.yaml\")\n",
    "config.model.params[\"ckpt_path\"] = f\"logs/a8_jd_lr10_4_14cls_JointLatentDiffusionMultilabel_2024-02-09T07-02-07/checkpoints/last.ckpt\"\n",
    "\n",
    "model = JointLatentDiffusionMultilabel(**config.model.get(\"params\", dict()))\n",
    "model.sampling_method='conditional_to_x'\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sample_grad_scale=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultilabelClassifier(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.3, inplace=False)\n",
       "      (1): Linear(in_features=2048, out_features=15, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (auroc_train): AUROC()\n",
       "  (auroc_val): AUROC()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "config = OmegaConf.load(\"/home/jk/Joint-Diffusion-in-Latent-Space/logs/d14_resnet_aug8_100_MultilabelClassifier_2024-02-08T23-03-18/configs/config.yaml\")\n",
    "ckpt_path = f\"/home/jk/Joint-Diffusion-in-Latent-Space/logs/d14_resnet_aug8_100_MultilabelClassifier_2024-02-08T23-03-18/checkpoints/last.ckpt\"\n",
    "\n",
    "model_2 = MultilabelClassifier(**config.model.get(\"params\", dict()))\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "model_2.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model_2.to(device)\n",
    "model_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_imgs(model, data_loader, max_samples=10):\n",
    "    # Encode all images in the data_laoder using model, and return both images and encodings\n",
    "    img_list, embed_list, bbox_list, label_list = [], [], [], []\n",
    "\n",
    "    for imgs, bbox, label in tqdm(data_loader):\n",
    "        if len(imgs.shape) == 3:\n",
    "            imgs = imgs[..., None]\n",
    "        imgs = rearrange(imgs, 'b h w c -> b c h w')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_posterior = model.encode_first_stage(imgs.to(device))\n",
    "            latent = model.get_first_stage_encoding(encoder_posterior).detach()\n",
    "            img_list.append(imgs.cpu())\n",
    "            embed_list.append(latent.cpu())\n",
    "            bbox_list.append(bbox)\n",
    "            label_list.append(label)\n",
    "        if max_samples is not None and len(img_list) > max_samples:\n",
    "            break\n",
    "    return (img_list, embed_list, bbox_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardiomegaly has N samples:  146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] models/latent_diffusion/joint_latent_diffusion_multilabel.py, p_sample_loop: return_pred_o not implemented for every case\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling t:  18%|█▊        | 55/300 [02:56<18:35,  4.55s/it]"
     ]
    }
   ],
   "source": [
    "cl_list = [\"Atelectasis\",\"Cardiomegaly\",\"Consolidation\",\"Edema\",\"Effusion\",\"Emphysema\",\"Fibrosis\", \"Hernia\",\"Infiltration\", \"Mass\", \"Nodule\",\"Pleural_Thickening\",\"Pneumonia\",\"Pneumothorax\",\"No Finding\"]\n",
    "dl_dict = {}\n",
    "T = 300\n",
    "num_timesteps = 1000\n",
    "\n",
    "for class_ in cl_list[1:2]:\n",
    "    dataset = ChestXRay_nih_bbox(pick_class=class_)\n",
    "    if len(dataset)>0:\n",
    "        print(class_, 'has N samples: ', len(dataset))\n",
    "        dl_dict[class_] = torch.utils.data.DataLoader(dataset, batch_size=min(len(dataset), 256), shuffle=False)\n",
    "\n",
    "        ret = embed_imgs(model, dl_dict[class_])\n",
    "        batch=0\n",
    "        for img_original, z, bbox in zip(ret[0], ret[1], ret[2]):\n",
    "            z = z.to(model.device)\n",
    "            t = repeat(torch.tensor([T]), '1 -> b', b=len(z))\n",
    "            t = t.to(model.device).long()\n",
    "            noise = torch.randn_like(z)\n",
    "            z_noisy = model.q_sample(x_start=z, t=t, noise=noise)\n",
    "            shape = z_noisy.shape\n",
    "            samples, pred_o = model.p_sample_loop(cond=None, shape = shape, original_img = z, \n",
    "                                                  return_intermediates=False, x_T=z_noisy, start_T=T, \n",
    "                                                  pick_class=class_, return_pred_o=True)\n",
    "            x_samples = model.decode_first_stage(samples)\n",
    "            torch.save(x_samples, f'vce_results/{class_}_T{T}_b{batch}_x_samples.pt')\n",
    "            torch.save(pred_o, f'vce_results/{class_}_T{T}_b{batch}_pred_o.pt')\n",
    "            batch+=1\n",
    "        #here appennd all images per class to one tensor and put them into dict\n",
    "            #break\n",
    "        #\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT IMGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Plot the images on the subplots\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m denoised_guided_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mx_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_from_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m denoised_guided \u001b[38;5;241m=\u001b[39m denoised_guided_normalized\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m      9\u001b[0m img_ref_normalized \u001b[38;5;241m=\u001b[39m img_original\u001b[38;5;241m.\u001b[39mcpu()[idx_from_batch]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAAFlCAYAAABrxYI/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhUElEQVR4nO3df2zc5X0H8I/t4DOo2IRlcX7MNIOO0hZIaEI8QxGi8moJlC5/TPWgSrKIH6PNEI21lYRAXEobZwxQpBIakcLoH2VJiwBVTWTKvEYVxVPUJJboSEA00GRVbZJ12FlobWJ/90eEXTfnJOfEj+3j9ZLuD3/7PHfPB7vv6O0735VkWZYFAAAAMKZKx/sAAAAA8GGggAMAAEACCjgAAAAkoIADAABAAgo4AAAAJKCAAwAAQAIKOAAAACSggAMAAEACCjgAAAAkoIADAABAAgUX8J/+9KexaNGimDVrVpSUlMQLL7xwyj07duyIT3/605HL5eJjH/tYPP3006M4KsDEJh8B8pOPAMcVXMCPHj0ac+fOjY0bN57W+rfeeituuummuOGGG6KjoyO+8pWvxG233RYvvvhiwYcFmMjkI0B+8hHguJIsy7JRby4pieeffz4WL1484pp77rkntm3bFr/4xS8Gr/3t3/5tvPvuu9Ha2jrahwaY0OQjQH7yEfgwmzLWD9De3h719fXDrjU0NMRXvvKVEff09vZGb2/v4NcDAwPx29/+Nv7kT/4kSkpKxuqoQJHKsiyOHDkSs2bNitLSifPWF/IRGG/yEWBkY5GRY17AOzs7o7q6eti16urq6Onpid/97ndx7rnnnrCnpaUlHnjggbE+GvAhc/DgwfizP/uz8T7GIPkITBTyEWBkZzMjx7yAj8bq1aujqalp8Ovu7u646KKL4uDBg1FZWTmOJwMmo56enqipqYnzzz9/vI9yxuQjcDbJR4CRjUVGjnkBnzFjRnR1dQ271tXVFZWVlXl/exkRkcvlIpfLnXC9srJSgAKjNtFegigfgYlCPgKM7Gxm5Jj/sU9dXV20tbUNu/bSSy9FXV3dWD80wIQmHwHyk49AsSq4gP/f//1fdHR0REdHR0Qc/5iIjo6OOHDgQEQcf/nP0qVLB9ffeeedsX///vjqV78a+/bti8cffzy+//3vx8qVK8/OBAAThHwEyE8+AhxXcAH/+c9/HldddVVcddVVERHR1NQUV111VaxduzYiIn7zm98MhmlExJ//+Z/Htm3b4qWXXoq5c+fGI488Et/5zneioaHhLI0AMDHIR4D85CPAcWf0OeCp9PT0RFVVVXR3d/sbHqBgxZwhxTwbMPaKOUOKeTYgjbHIkYnzgY8AAABQxBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgARGVcA3btwYc+bMiYqKiqitrY2dO3eedP2GDRvi4x//eJx77rlRU1MTK1eujN///vejOjDARCYfAfKTjwCjKOBbt26NpqamaG5ujt27d8fcuXOjoaEh3nnnnbzrn3nmmVi1alU0NzfH3r1748knn4ytW7fGvffee8aHB5hI5CNAfvIR4LiCC/ijjz4at99+eyxfvjw++clPxqZNm+K8886Lp556Ku/6V155Ja699tq45ZZbYs6cOfG5z30ubr755lP+1hNgspGPAPnJR4DjCirgfX19sWvXrqivrx+6g9LSqK+vj/b29rx7rrnmmti1a9dgYO7fvz+2b98eN95444iP09vbGz09PcNuABOZfATITz4CDJlSyOLDhw9Hf39/VFdXD7teXV0d+/bty7vnlltuicOHD8dnPvOZyLIsjh07FnfeeedJX0LU0tISDzzwQCFHAxhX8hEgP/kIMGTM3wV9x44dsW7dunj88cdj9+7d8dxzz8W2bdviwQcfHHHP6tWro7u7e/B28ODBsT4mQHLyESA/+QgUq4KeAZ82bVqUlZVFV1fXsOtdXV0xY8aMvHvuv//+WLJkSdx2220REXHFFVfE0aNH44477og1a9ZEaemJvwPI5XKRy+UKORrAuJKPAPnJR4AhBT0DXl5eHvPnz4+2trbBawMDA9HW1hZ1dXV597z33nsnhGRZWVlERGRZVuh5ASYk+QiQn3wEGFLQM+AREU1NTbFs2bJYsGBBLFy4MDZs2BBHjx6N5cuXR0TE0qVLY/bs2dHS0hIREYsWLYpHH300rrrqqqitrY0333wz7r///li0aNFgkAIUA/kIkJ98BDiu4ALe2NgYhw4dirVr10ZnZ2fMmzcvWltbB99Y48CBA8N+Y3nfffdFSUlJ3HffffHrX/86/vRP/zQWLVoU3/zmN8/eFAATgHwEyE8+AhxXkk2C1/H09PREVVVVdHd3R2Vl5XgfB5hkijlDink2YOwVc4YU82xAGmORI2P+LugAAACAAg4AAABJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJjKqAb9y4MebMmRMVFRVRW1sbO3fuPOn6d999N1asWBEzZ86MXC4Xl156aWzfvn1UBwaYyOQjQH7yESBiSqEbtm7dGk1NTbFp06aora2NDRs2RENDQ7z++usxffr0E9b39fXFX/3VX8X06dPj2WefjdmzZ8evfvWruOCCC87G+QEmDPkIkJ98BDiuJMuyrJANtbW1cfXVV8djjz0WEREDAwNRU1MTd911V6xateqE9Zs2bYp/+Zd/iX379sU555wzqkP29PREVVVVdHd3R2Vl5ajuA/jwSpUh8hGYbOQjwMjGIkcKegl6X19f7Nq1K+rr64fuoLQ06uvro729Pe+eH/7wh1FXVxcrVqyI6urquPzyy2PdunXR398/4uP09vZGT0/PsBvARCYfAfKTjwBDCirghw8fjv7+/qiurh52vbq6Ojo7O/Pu2b9/fzz77LPR398f27dvj/vvvz8eeeSR+MY3vjHi47S0tERVVdXgraamppBjAiQnHwHyk48AQ8b8XdAHBgZi+vTp8cQTT8T8+fOjsbEx1qxZE5s2bRpxz+rVq6O7u3vwdvDgwbE+JkBy8hEgP/kIFKuC3oRt2rRpUVZWFl1dXcOud3V1xYwZM/LumTlzZpxzzjlRVlY2eO0Tn/hEdHZ2Rl9fX5SXl5+wJ5fLRS6XK+RoAONKPgLkJx8BhhT0DHh5eXnMnz8/2traBq8NDAxEW1tb1NXV5d1z7bXXxptvvhkDAwOD1954442YOXNm3vAEmIzkI0B+8hFgSMEvQW9qaorNmzfHd7/73di7d2986UtfiqNHj8by5csjImLp0qWxevXqwfVf+tKX4re//W3cfffd8cYbb8S2bdti3bp1sWLFirM3BcAEIB8B8pOPAMcV/DngjY2NcejQoVi7dm10dnbGvHnzorW1dfCNNQ4cOBClpUO9vqamJl588cVYuXJlXHnllTF79uy4++6745577jl7UwBMAPIRID/5CHBcwZ8DPh58jiNwJoo5Q4p5NmDsFXOGFPNsQBrj/jngAAAAwOgo4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJjKqAb9y4MebMmRMVFRVRW1sbO3fuPK19W7ZsiZKSkli8ePFoHhZgwpOPAPnJR4BRFPCtW7dGU1NTNDc3x+7du2Pu3LnR0NAQ77zzzkn3vf322/GP//iPcd111436sAATmXwEyE8+AhxXcAF/9NFH4/bbb4/ly5fHJz/5ydi0aVOcd9558dRTT424p7+/P774xS/GAw88EBdffPEZHRhgopKPAPnJR4DjCirgfX19sWvXrqivrx+6g9LSqK+vj/b29hH3ff3rX4/p06fHrbfeelqP09vbGz09PcNuABOZfATITz4CDCmogB8+fDj6+/ujurp62PXq6uro7OzMu+fll1+OJ598MjZv3nzaj9PS0hJVVVWDt5qamkKOCZCcfATITz4CDBnTd0E/cuRILFmyJDZv3hzTpk077X2rV6+O7u7uwdvBgwfH8JQA6clHgPzkI1DMphSyeNq0aVFWVhZdXV3Drnd1dcWMGTNOWP/LX/4y3n777Vi0aNHgtYGBgeMPPGVKvP7663HJJZecsC+Xy0UulyvkaADjSj4C5CcfAYYU9Ax4eXl5zJ8/P9ra2gavDQwMRFtbW9TV1Z2w/rLLLotXX301Ojo6Bm+f//zn44YbboiOjg4vDQKKhnwEyE8+Agwp6BnwiIimpqZYtmxZLFiwIBYuXBgbNmyIo0ePxvLlyyMiYunSpTF79uxoaWmJioqKuPzyy4ftv+CCCyIiTrgOMNnJR4D85CPAcQUX8MbGxjh06FCsXbs2Ojs7Y968edHa2jr4xhoHDhyI0tIx/dNygAlJPgLkJx8BjivJsiwb70OcSk9PT1RVVUV3d3dUVlaO93GASaaYM6SYZwPGXjFnSDHPBqQxFjniV40AAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACYyqgG/cuDHmzJkTFRUVUVtbGzt37hxx7ebNm+O6666LqVOnxtSpU6O+vv6k6wEmM/kIkJ98BBhFAd+6dWs0NTVFc3Nz7N69O+bOnRsNDQ3xzjvv5F2/Y8eOuPnmm+MnP/lJtLe3R01NTXzuc5+LX//612d8eICJRD4C5CcfAY4rybIsK2RDbW1tXH311fHYY49FRMTAwEDU1NTEXXfdFatWrTrl/v7+/pg6dWo89thjsXTp0tN6zJ6enqiqqoru7u6orKws5LgAyTJEPgKTjXwEGNlY5EhBz4D39fXFrl27or6+fugOSkujvr4+2tvbT+s+3nvvvXj//ffjwgsvLOykABOYfATITz4CDJlSyOLDhw9Hf39/VFdXD7teXV0d+/btO637uOeee2LWrFnDQviP9fb2Rm9v7+DXPT09hRwTIDn5CJCffAQYkvRd0NevXx9btmyJ559/PioqKkZc19LSElVVVYO3mpqahKcESE8+AuQnH4FiUlABnzZtWpSVlUVXV9ew611dXTFjxoyT7n344Ydj/fr18eMf/ziuvPLKk65dvXp1dHd3D94OHjxYyDEBkpOPAPnJR4AhBRXw8vLymD9/frS1tQ1eGxgYiLa2tqirqxtx30MPPRQPPvhgtLa2xoIFC075OLlcLiorK4fdACYy+QiQn3wEGFLQ34BHRDQ1NcWyZctiwYIFsXDhwtiwYUMcPXo0li9fHhERS5cujdmzZ0dLS0tERPzzP/9zrF27Np555pmYM2dOdHZ2RkTERz7ykfjIRz5yFkcBGF/yESA/+QhwXMEFvLGxMQ4dOhRr166Nzs7OmDdvXrS2tg6+scaBAweitHToifVvf/vb0dfXF3/zN38z7H6am5vja1/72pmdHmACkY8A+clHgOMK/hzw8eBzHIEzUcwZUsyzAWOvmDOkmGcD0hj3zwEHAAAARkcBBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhgVAV848aNMWfOnKioqIja2trYuXPnSdf/4Ac/iMsuuywqKiriiiuuiO3bt4/qsAATnXwEyE8+AoyigG/dujWampqiubk5du/eHXPnzo2GhoZ455138q5/5ZVX4uabb45bb7019uzZE4sXL47FixfHL37xizM+PMBEIh8B8pOPAMeVZFmWFbKhtrY2rr766njsscciImJgYCBqamrirrvuilWrVp2wvrGxMY4ePRo/+tGPBq/95V/+ZcybNy82bdp0Wo/Z09MTVVVV0d3dHZWVlYUcFyBZhshHYLKRjwAjG4scmVLI4r6+vti1a1esXr168FppaWnU19dHe3t73j3t7e3R1NQ07FpDQ0O88MILIz5Ob29v9Pb2Dn7d3d0dEcf/AwAU6oPsKPD3jQWRj8BkJB8BRjYWGVlQAT98+HD09/dHdXX1sOvV1dWxb9++vHs6Ozvzru/s7BzxcVpaWuKBBx444XpNTU0hxwUY5n/+53+iqqpqTO5bPgKTmXwEGNnZzMiCCngqq1evHvZbz3fffTc++tGPxoEDB8bsH4fx0NPTEzU1NXHw4MGie2mU2SanYp2tu7s7LrroorjwwgvH+yhn7MOSjxHF+/NYrHNFmG0yko+TU7H+PEYU72zFOldEcc82FhlZUAGfNm1alJWVRVdX17DrXV1dMWPGjLx7ZsyYUdD6iIhcLhe5XO6E61VVVUX3TY2IqKysLMq5Isw2WRXrbKWlY/fJi/Jx7BTrz2OxzhVhtslIPk5OxfrzGFG8sxXrXBHFPdvZzMiC7qm8vDzmz58fbW1tg9cGBgaira0t6urq8u6pq6sbtj4i4qWXXhpxPcBkJB8B8pOPAEMKfgl6U1NTLFu2LBYsWBALFy6MDRs2xNGjR2P58uUREbF06dKYPXt2tLS0RETE3XffHddff3088sgjcdNNN8WWLVvi5z//eTzxxBNndxKAcSYfAfKTjwDHFVzAGxsb49ChQ7F27dro7OyMefPmRWtr6+AbZRw4cGDYU/TXXHNNPPPMM3HffffFvffeG3/xF38RL7zwQlx++eWn/Zi5XC6am5vzvqxoMivWuSLMNlkV62yp5pKPZ1exzlasc0WYbTKSj5OT2SafYp0rwmyFKvhzwAEAAIDCjd07bgAAAACDFHAAAABIQAEHAACABBRwAAAASGDCFPCNGzfGnDlzoqKiImpra2Pnzp0nXf+DH/wgLrvssqioqIgrrrgitm/fnuikhSlkrs2bN8d1110XU6dOjalTp0Z9ff0p/zuMp0K/Zx/YsmVLlJSUxOLFi8f2gGeg0NnefffdWLFiRcycOTNyuVxceumlE/JnstC5NmzYEB//+Mfj3HPPjZqamli5cmX8/ve/T3Ta0/fTn/40Fi1aFLNmzYqSkpJ44YUXTrlnx44d8elPfzpyuVx87GMfi6effnrMzzlaxZqPEcWbkfJxyGTJx4jizEj5OJx8nBiKNSPl4xD5eBLZBLBly5asvLw8e+qpp7L/+q//ym6//fbsggsuyLq6uvKu/9nPfpaVlZVlDz30UPbaa69l9913X3bOOedkr776auKTn1yhc91yyy3Zxo0bsz179mR79+7N/u7v/i6rqqrK/vu//zvxyU+t0Nk+8NZbb2WzZ8/Orrvuuuyv//qv0xy2QIXO1tvbmy1YsCC78cYbs5dffjl76623sh07dmQdHR2JT35yhc71ve99L8vlctn3vve97K233spefPHFbObMmdnKlSsTn/zUtm/fnq1ZsyZ77rnnsojInn/++ZOu379/f3beeedlTU1N2WuvvZZ961vfysrKyrLW1tY0By5AseZjlhVvRsrHIZMlH7OseDNSPg6RjxNDsWakfBwiH09uQhTwhQsXZitWrBj8ur+/P5s1a1bW0tKSd/0XvvCF7Kabbhp2rba2Nvv7v//7MT1noQqd648dO3YsO//887Pvfve7Y3XEURvNbMeOHcuuueaa7Dvf+U62bNmyCRmeWVb4bN/+9reziy++OOvr60t1xFEpdK4VK1Zkn/3sZ4dda2pqyq699toxPeeZOp0A/epXv5p96lOfGnatsbExa2hoGMOTjU6x5mOWFW9GyschkyUfs+zDkZHyUT5OBMWakfJxiHw8uXF/CXpfX1/s2rUr6uvrB6+VlpZGfX19tLe3593T3t4+bH1ERENDw4jrx8No5vpj7733Xrz//vtx4YUXjtUxR2W0s33961+P6dOnx6233primKMymtl++MMfRl1dXaxYsSKqq6vj8ssvj3Xr1kV/f3+qY5/SaOa65pprYteuXYMvMdq/f39s3749brzxxiRnHkuTIUMiijcfI4o3I+XjcJMhHyNk5B8q5gwp5tn+2ETMx4jizUj5OJx8PLkpZ/NQo3H48OHo7++P6urqYderq6tj3759efd0dnbmXd/Z2Tlm5yzUaOb6Y/fcc0/MmjXrhG/0eBvNbC+//HI8+eST0dHRkeCEozea2fbv3x//8R//EV/84hdj+/bt8eabb8aXv/zleP/996O5uTnFsU9pNHPdcsstcfjw4fjMZz4TWZbFsWPH4s4774x77703xZHH1EgZ0tPTE7/73e/i3HPPHaeTDVes+RhRvBkpH4ebDPkYISP/kHwcf8WajxHFm5HycTj5eHLj/gw4+a1fvz62bNkSzz//fFRUVIz3cc7IkSNHYsmSJbF58+aYNm3aeB/nrBsYGIjp06fHE088EfPnz4/GxsZYs2ZNbNq0abyPdkZ27NgR69ati8cffzx2794dzz33XGzbti0efPDB8T4aFE1GysfJS0YyURVLPkYUd0bKxw+vcX8GfNq0aVFWVhZdXV3Drnd1dcWMGTPy7pkxY0ZB68fDaOb6wMMPPxzr16+Pf//3f48rr7xyLI85KoXO9stf/jLefvvtWLRo0eC1gYGBiIiYMmVKvP7663HJJZeM7aFP02i+bzNnzoxzzjknysrKBq994hOfiM7Ozujr64vy8vIxPfPpGM1c999/fyxZsiRuu+22iIi44oor4ujRo3HHHXfEmjVrorR08v7+bqQMqaysnDDP7kQUbz5GFG9GysfhJkM+RsjIPyQfx1+x5mNE8WakfBxOPp7cuE9fXl4e8+fPj7a2tsFrAwMD0dbWFnV1dXn31NXVDVsfEfHSSy+NuH48jGauiIiHHnooHnzwwWhtbY0FCxakOGrBCp3tsssui1dffTU6OjoGb5///OfjhhtuiI6OjqipqUl5/JMazfft2muvjTfffHPwH4SIiDfeeCNmzpw5YcJzNHO99957JwTkB/9IHH+vislrMmRIRPHmY0TxZqR8HG4y5GOEjPxDxZwhxTxbxMTPx4jizUj5OJx8PIWC3rJtjGzZsiXL5XLZ008/nb322mvZHXfckV1wwQVZZ2dnlmVZtmTJkmzVqlWD63/2s59lU6ZMyR5++OFs7969WXNz84T8GIlC51q/fn1WXl6ePfvss9lvfvObwduRI0fGa4QRFTrbH5uo72CZZYXPduDAgez888/P/uEf/iF7/fXXsx/96EfZ9OnTs2984xvjNUJehc7V3NycnX/++dm//du/Zfv3789+/OMfZ5dcckn2hS98YbxGGNGRI0eyPXv2ZHv27MkiInv00UezPXv2ZL/61a+yLMuyVatWZUuWLBlc/8HHSPzTP/1Ttnfv3mzjxo0T+mN2ijEfs6x4M1I+Tr58zLLizUj5KB8nmmLNSPkoH0/XhCjgWZZl3/rWt7KLLrooKy8vzxYuXJj953/+5+D/dv3112fLli0btv773/9+dumll2bl5eXZpz71qWzbtm2JT3x6Cpnrox/9aBYRJ9yam5vTH/w0FPo9+0MTNTw/UOhsr7zySlZbW5vlcrns4osvzr75zW9mx44dS3zqUytkrvfffz/72te+ll1yySVZRUVFVlNTk335y1/O/vd//zf9wU/hJz/5Sd7/73wwz7Jly7Lrr7/+hD3z5s3LysvLs4svvjj713/91+TnPl3Fmo9ZVrwZKR+HTJZ8zLLizEj5uGzYevk4MRRrRsrH4+TjyZVk2SR+HQAAAABMEuP+N+AAAADwYaCAAwAAQAIKOAAAACSggAMAAEACCjgAAAAkoIADAABAAgo4AAAAJKCAAwAAQAIKOAAAACSggAMAAEACCjgAAAAkoIADAABAAv8PErIwn8QKNHkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "idx_from_batch = 1\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "\n",
    "# Plot the images on the subplots\n",
    "denoised_guided_normalized = x_samples.cpu()[idx_from_batch].permute(1,2,0)\n",
    "denoised_guided = denoised_guided_normalized*0.5+0.5\n",
    "img_ref_normalized = img_original.cpu()[idx_from_batch].permute(1,2,0)\n",
    "img_ref = img_ref_normalized*0.5+0.5\n",
    "diff = abs(denoised_guided - img_ref)\n",
    "\n",
    "ax = 0\n",
    "axes[ax].imshow(denoised_guided, cmap='gray')\n",
    "axes[ax].axis('off')\n",
    "\n",
    "ax +=1\n",
    "axes[ax].imshow(img_ref, cmap='gray')\n",
    "axes[ax].axis('off')\n",
    "\n",
    "ax +=1\n",
    "\n",
    "\n",
    "x, y, w, h = bbox[idx_from_batch][0], bbox[idx_from_batch][1],bbox[idx_from_batch][2], bbox[idx_from_batch][3]\n",
    "# Scale the bounding box coordinates from 1024x1024 to 256x256\n",
    "scaled_x = x * 0.25\n",
    "scaled_y = y * 0.25\n",
    "scaled_w = w * 0.25\n",
    "scaled_h = h * 0.25\n",
    "\n",
    "# Create a rectangle patch using the scaled coordinates\n",
    "rect = patches.Rectangle((scaled_x, scaled_y), scaled_w, scaled_h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "# Add the rectangle patch to the plot\n",
    "axes[ax].add_patch(rect)\n",
    "\n",
    "\n",
    "axes[ax].imshow(diff)\n",
    "axes[ax].axis('off')\n",
    "\n",
    "fig.suptitle(ret[3][0][idx_from_batch])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all predictins for orig x tensor([[0.0448, 0.0227, 0.0592, 0.0434, 0.0853, 0.3595, 0.0105, 0.0034, 0.2841,\n",
      "         0.0367, 0.0589, 0.0298, 0.0149, 0.2983, 0.3050]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "all predictins for x pred start tensor([[0.0362, 0.0445, 0.0669, 0.0741, 0.1025, 0.0698, 0.0104, 0.0025, 0.3458,\n",
      "         0.0253, 0.0581, 0.0238, 0.0237, 0.1173, 0.3283]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "predicitons for x original, only class Cardiomegaly tensor([[0.0227]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "predicitons for x pred start, only class Cardiomegaly tensor([[0.0445]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred_o = model_2(img_ref_normalized.permute(2,0,1).unsqueeze(0).cuda())\n",
    "pred = model_2(denoised_guided_normalized.permute(2,0,1).unsqueeze(0).cuda())\n",
    "cl_list = [\"Atelectasis\",\"Cardiomegaly\",\"Consolidation\",\"Edema\",\"Effusion\",\"Emphysema\",\"Fibrosis\", \"Hernia\",\"Infiltration\", \"Mass\", \"Nodule\",\"Pleural_Thickening\",\"Pneumonia\",\"Pneumothorax\",\"No Finding\"]\n",
    "id_class = cl_list.index(pick_class)\n",
    "print('all predictins for orig x', torch.nn.functional.sigmoid(pred_o))\n",
    "print('all predictins for x pred start', torch.nn.functional.sigmoid(pred))\n",
    "print(f'predicitons for x original, only class {cl_list[id_class]}', torch.nn.functional.sigmoid(pred_o[:,[id_class]]))\n",
    "print(f'predicitons for x pred start, only class {cl_list[id_class]}',torch.nn.functional.sigmoid(pred[:,[id_class]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
