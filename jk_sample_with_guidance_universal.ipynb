{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from omegaconf import OmegaConf\n",
    "import argparse\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from models import get_model_class\n",
    "from os import path, environ\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from ldm.util import default\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    environ[\"WANDB__SERVICE_WAIT\"] = \"300\"\n",
    "\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--path\", \"-p\", type=Path, required=True, help=\"path to config file\")\n",
    "    # parser.add_argument(\"--checkpoint\", \"-c\", type=Path, required=False, help=\"path to model checkpoint file\")\n",
    "    # args = parser.parse_args()\n",
    "    # config_path = str(args.path)\n",
    "    # checkpoint_path = str(args.checkpoint) if args.checkpoint is not None else None\n",
    "\n",
    "    # config = OmegaConf.load(config_path)\n",
    "    config = OmegaConf.load(\"configs/standard_diffusion/semi-supervised/diffmatch_pooling/25_per_class/svhn.yaml\")\n",
    "\n",
    "    # if checkpoint_path is not None:\n",
    "    #     config.model.params[\"ckpt_path\"] = checkpoint_path\n",
    "    config.model.params[\"ckpt_path\"] = \"./svhn_fid_test.ckpt\"\n",
    "\n",
    "    model = get_model_class(config.model.get(\"model_type\"))(**config.model.get(\"params\", dict()))\n",
    "\n",
    "    # i = 0\n",
    "    ds = tv.datasets.CIFAR10(\"./data\", True, tv.transforms.ToTensor())\n",
    "    # for img, y in ds:\n",
    "    #     picture = tv.transforms.functional.to_pil_image(img)\n",
    "    #     picture.save(f\"./cifar100/img{i}.png\", \"PNG\")\n",
    "    #     i += 1\n",
    "    cuda = torch.device(\"cuda\")\n",
    "    model.to(cuda)\n",
    "    model.sampling_method = \"conditional_to_x\"\n",
    "    model.sample_grad_scale = 300\n",
    "\n",
    "    # mean = [0.4914, 0.4822, 0.4465]\n",
    "    # std = [0.2471, 0.2435, 0.2616]\n",
    "    mean = [0.5, 0.5, 0.5]\n",
    "    std = [0.5, 0.5, 0.5]\n",
    "    batch_size = 53\n",
    "    num_batches = 1\n",
    "    classes = 10\n",
    "    img_list = [f\"./cifar10_samples/img{i}.png\" for i in range(8, 68) if i not in [62, 54, 53, 46, 45, 37, 31]]\n",
    "    target_classes = [8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 3]\n",
    "    t_start = 200\n",
    "\n",
    "    denormalize = tv.transforms.Compose(\n",
    "        [\n",
    "            tv.transforms.Normalize(mean=[0., 0., 0.], std=[1 / s for s in std]),\n",
    "            tv.transforms.Normalize(mean=[-m for m in mean], std=[1., 1., 1.]),\n",
    "        ]\n",
    "    )\n",
    "    normalize = tv.transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    transform = tv.transforms.ToTensor()\n",
    "    img_list = [normalize(transform(Image.open(img))).unsqueeze(dim=0) for img in img_list]\n",
    "\n",
    "    images = torch.concat(img_list).to(model.device)\n",
    "    noise = default(None, lambda: torch.randn_like(images))\n",
    "    noised = model.q_sample(images.to(model.device), t=torch.tensor([t_start for _ in range(len(images))], device=model.device).long(), noise=noise)\n",
    "\n",
    "    model.sample_classes = torch.tensor(target_classes, device=cuda)\n",
    "    samples = model.sample(len(target_classes), x_start=noised, t_start=t_start)\n",
    "    samples = samples.cpu()\n",
    "    samples = denormalize(samples)\n",
    "    to_show = torch.concat((denormalize(images.cpu()), denormalize(noised.cpu()), samples))\n",
    "    grid_img = tv.utils.make_grid(to_show, nrow=len(target_classes))\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "    unet = model.model.diffusion_model\n",
    "    representations = unet.just_representations(samples.to(cuda), torch.zeros_like(model.sample_classes), context=None, pooled=False)\n",
    "    pooled_representations = model.transform_representations(representations)\n",
    "    pred = model.classifier(pooled_representations)\n",
    "    print(torch.nn.functional.softmax(pred, dim=-1).max(dim=-1).values, torch.argmax(pred, dim=-1))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
